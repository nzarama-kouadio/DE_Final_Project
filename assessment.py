import pandas as pd  # Step 1: Import necessary library

# Step 2: Load Locust stats CSV file
# This file contains data generated by Locust during the load test.
# Replace 'locust_results_stats.csv' with the path to your file if it's in a different location.
data = pd.read_csv("locust_results_stats.csv")  # put the correct file

# Step 3: Display the first few rows of the data for verification
# This helps confirm that the CSV file loaded correctly.
print("First few rows of the dataset:")
print(data.head())

# Step 4: Calculate overall throughput
# Throughput is the total number of successful requests handled per second.
total_throughput = data["Requests/s"].sum()

# Step 5: Identify the maximum and average response times
# - Max Response Time: The longest time taken for a request to complete.
# - Average Response Time: The average time taken for all requests.
max_response_time = data["Max Response Time"].max()
avg_response_time = data["Average Response Time"].mean()

# Step 6: Calculate the failure rate
# Failure rate is the percentage of requests that resulted in errors (e.g., HTTP 4xx/5xx).
# Formula: (total failures / total requests) * 100
total_requests = data["Request Count"].sum()
total_failures = data["Failure Count"].sum()
failure_rate = (total_failures / total_requests) * 100 if total_requests > 0 else 0

# Step 7: Display the calculated metrics
# Print the results in a readable format for easy interpretation.
print("\nPerformance Metrics:")
print(f"Total Throughput: {total_throughput:.2f} requests/sec")
print(f"Max Response Time: {max_response_time} ms")
print(f"Average Response Time: {avg_response_time:.2f} ms")
print(f"Failure Rate: {failure_rate:.2f}%")
